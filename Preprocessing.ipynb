{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfmVqlY2V4Pw"
      },
      "outputs": [],
      "source": [
        " #... (NLTK downloads and UMLS API details)\n",
        "# Initialize lemmatizer and stop words\n",
        "#Import necessary Libraries\n",
        "import nltk\n",
        "import requests\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm  # Import tqdm for progress bar\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Download NLTK resources if not already downloaded\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Define UMLS API details\n",
        "UMLS_API_KEY = \"\" #Enter Key here\n",
        "UMLS_API_URL = \"https://uts-ws.nlm.nih.gov/rest\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErTqzQYrZB7Z"
      },
      "source": [
        "***-----------------------------------------------------***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkzUPcj_YrjD"
      },
      "source": [
        "**Extracting semantic features for the filtered dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6VosUjQul9V"
      },
      "source": [
        "**--------------------------------------**\n",
        "New start point: df with cuis, concept_names, uris:\n",
        "**Add semantic types, relations, semantic group columns/features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kb7UgJWyZypD",
        "outputId": "2248d43f-02fd-4e15-dc6c-411ec37f8f10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 TEXT ABBREV  \\\n",
              "0   Cost-effectiveness of pentostatin compared wit...    hcl   \n",
              "1   Which role for rituximab in hairy cell leukemi...    hcl   \n",
              "2   Risk of additional cancers in untreated and tr...    hcl   \n",
              "3   Importance of minimal residual disease in hair...    hcl   \n",
              "4   Combination therapies to improve the long-term...    hcl   \n",
              "5   The biology of hairy cell leukemia.As in all m...    hcl   \n",
              "6   Hairy cell leukemia responsive to anti-thymocy...    hcl   \n",
              "7   T-box-expressed-in-T-cells (T-bet) expression ...    hcl   \n",
              "8   Characterisation of hairy cell leukaemia by ti...    hcl   \n",
              "9   Phase II trial of recombinant immunotoxin RFB4...    hcl   \n",
              "10  Risk factors for severe infection in patients ...    hcl   \n",
              "11  Immunophenotypic analysis of CD103+ B-lymphopr...    hcl   \n",
              "12  Visual disturbance as initial presentation of ...    hcl   \n",
              "13  Paraneoplastic vasculitis associated with hair...    hcl   \n",
              "14  A case of Mollitias and Fragilitas Ossium - un...    hcl   \n",
              "15  Extranodal hairy cell leukemia presenting in t...    hcl   \n",
              "16  Therapeutic advances in leukemia and myelodysp...    hcl   \n",
              "17  Hairy cell leukemia: clinical, pathological an...    hcl   \n",
              "18  A novel CD11c monoclonal antibody effective in...    hcl   \n",
              "19  Underexpression of RhoH in Hairy Cell Leukemia...    hcl   \n",
              "\n",
              "                  ABBREV_CUI  \\\n",
              "0   ['C0023443', 'C0020259']   \n",
              "1   ['C0023443', 'C0020259']   \n",
              "2   ['C0023443', 'C0020259']   \n",
              "3   ['C0023443', 'C0020259']   \n",
              "4   ['C0023443', 'C0020259']   \n",
              "5   ['C0023443', 'C0020259']   \n",
              "6   ['C0023443', 'C0020259']   \n",
              "7   ['C0023443', 'C0020259']   \n",
              "8   ['C0023443', 'C0020259']   \n",
              "9   ['C0023443', 'C0020259']   \n",
              "10  ['C0023443', 'C0020259']   \n",
              "11  ['C0023443', 'C0020259']   \n",
              "12  ['C0023443', 'C0020259']   \n",
              "13  ['C0023443', 'C0020259']   \n",
              "14  ['C0023443', 'C0020259']   \n",
              "15  ['C0023443', 'C0020259']   \n",
              "16  ['C0023443', 'C0020259']   \n",
              "17  ['C0023443', 'C0020259']   \n",
              "18  ['C0023443', 'C0020259']   \n",
              "19  ['C0023443', 'C0020259']   \n",
              "\n",
              "                            abbrev_cui_semantic_types  \\\n",
              "0   [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "1   [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "2   [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "3   [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "4   [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "5   [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "6   [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "7   [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "8   [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "9   [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "10  [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "11  [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "12  [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "13  [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "14  [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "15  [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "16  [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "17  [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "18  [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "19  [['Neoplastic Process'], ['Indicator, Reagent,...   \n",
              "\n",
              "                                 abbrev_cui_relations LABEL_CUI  \\\n",
              "0   [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "1   [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "2   [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "3   [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "4   [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "5   [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "6   [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "7   [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "8   [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "9   [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "10  [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "11  [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "12  [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "13  [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "14  [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "15  [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "16  [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "17  [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "18  [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "19  [[('mapped_to', 'Hairy cell leukemia not havin...  C0023443   \n",
              "\n",
              "    LABEL_ENCODING GOLD_CUI_semantic_types  \n",
              "0               57      Neoplastic Process  \n",
              "1               57      Neoplastic Process  \n",
              "2               57      Neoplastic Process  \n",
              "3               57      Neoplastic Process  \n",
              "4               57      Neoplastic Process  \n",
              "5               57      Neoplastic Process  \n",
              "6               57      Neoplastic Process  \n",
              "7               57      Neoplastic Process  \n",
              "8               57      Neoplastic Process  \n",
              "9               57      Neoplastic Process  \n",
              "10              57      Neoplastic Process  \n",
              "11              57      Neoplastic Process  \n",
              "12              57      Neoplastic Process  \n",
              "13              57      Neoplastic Process  \n",
              "14              57      Neoplastic Process  \n",
              "15              57      Neoplastic Process  \n",
              "16              57      Neoplastic Process  \n",
              "17              57      Neoplastic Process  \n",
              "18              57      Neoplastic Process  \n",
              "19              57      Neoplastic Process  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecf3a82d-31aa-458d-92ff-56df79417a86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXT</th>\n",
              "      <th>ABBREV</th>\n",
              "      <th>ABBREV_CUI</th>\n",
              "      <th>abbrev_cui_semantic_types</th>\n",
              "      <th>abbrev_cui_relations</th>\n",
              "      <th>LABEL_CUI</th>\n",
              "      <th>LABEL_ENCODING</th>\n",
              "      <th>GOLD_CUI_semantic_types</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cost-effectiveness of pentostatin compared wit...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Which role for rituximab in hairy cell leukemi...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Risk of additional cancers in untreated and tr...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Importance of minimal residual disease in hair...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Combination therapies to improve the long-term...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The biology of hairy cell leukemia.As in all m...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Hairy cell leukemia responsive to anti-thymocy...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>T-box-expressed-in-T-cells (T-bet) expression ...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Characterisation of hairy cell leukaemia by ti...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Phase II trial of recombinant immunotoxin RFB4...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Risk factors for severe infection in patients ...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Immunophenotypic analysis of CD103+ B-lymphopr...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Visual disturbance as initial presentation of ...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Paraneoplastic vasculitis associated with hair...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>A case of Mollitias and Fragilitas Ossium - un...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Extranodal hairy cell leukemia presenting in t...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Therapeutic advances in leukemia and myelodysp...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Hairy cell leukemia: clinical, pathological an...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>A novel CD11c monoclonal antibody effective in...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Underexpression of RhoH in Hairy Cell Leukemia...</td>\n",
              "      <td>hcl</td>\n",
              "      <td>['C0023443', 'C0020259']</td>\n",
              "      <td>[['Neoplastic Process'], ['Indicator, Reagent,...</td>\n",
              "      <td>[[('mapped_to', 'Hairy cell leukemia not havin...</td>\n",
              "      <td>C0023443</td>\n",
              "      <td>57</td>\n",
              "      <td>Neoplastic Process</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecf3a82d-31aa-458d-92ff-56df79417a86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ecf3a82d-31aa-458d-92ff-56df79417a86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ecf3a82d-31aa-458d-92ff-56df79417a86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-28334ce7-8fa7-41b4-8fdb-c67f22e47dee\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28334ce7-8fa7-41b4-8fdb-c67f22e47dee')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-28334ce7-8fa7-41b4-8fdb-c67f22e47dee button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30649,\n  \"fields\": [\n    {\n      \"column\": \"TEXT\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30465,\n        \"samples\": [\n          \"Histochemical and histological evaluations of the effects of high incubation temperature on embryonic development of <e>thymus</e> and bursa of Fabricius in broiler chickens.1. The effects of experimentally induced heat-stress on the embryonic development of bursa of Fabricius and thymus of the chicken were investigated by means of histological and enzyme histochemical methods. 2. In the experiments, 250 fertile eggs of the Ross 308 broiler strain were divided into two groups. The control eggs were maintained under optimal conditions (378 degrees C and 65 +/- 2% relative humidity, RH) during the whole incubation period. Heat stressed eggs were maintained under normal conditions (378 degrees C and 65 +/- 2% RH) until the 10th d of incubation and then exposed continuously (24 h per d) to high temperature (388 degrees C and 65 +/- 2% RH). Blood and tissue samples were taken from 10 animals of each group at d 13, 15, 18 and 21 of incubation and at d 2, 4 and 7 post-hatch. Tissue samples were processed for enzyme histochemical methods in addition to routine histological techniques. 3. The results revealed that egg temperatures were higher than incubator air temperature. Long-term heat-stress (401-406 degrees C egg temperature) retarded development of thymus and bursa of Fabricius. Peripheral blood ACP-ase and ANAE-positive lymphocyte levels of heat-stressed animals were lower than in the controls. 4. These results give some morphological evidence for immunosuppression induced by high temperature exposure during the embryonic development. Temperature distribution and air circulation in incubator should be questioned in the case of lower broiler flock immunity.\",\n          \"Comparison of anticancer drug coverage decisions in the United States and United Kingdom: does the evidence support the rhetoric?PURPOSE: In contrast to the United States, several European countries have health technology assessment programs for drugs, many of which assess cost effectiveness. Coverage decisions that consider cost effectiveness may lead to restrictions in access. METHODS: For a purposive sample of five decision-making bodies, we analyzed <e>US</e> and United Kingdom coverage decisions on all anticancer drugs approved by the US Food and Drug Administration (FDA) from 2004 to 2008. Data sources for the timing and outcome of licensing and coverage decisions included published and unpublished documentation, Web sites, and personal communication. RESULTS: The FDA approved 59 anticancer drugs over the study period, of which 46 were also approved by the European Medicines Agency. In the United States, 100% of drugs were covered, mostly without restriction. However, the United Kingdom bodies made positive coverage decisions for less than half of licensed drugs (National Institute for Health and Clinical Excellence [NICE]: 39%; Scottish Medicines Consortium [SMC]: 43%). Whereas the Centers for Medicare and Medicaid Services (CMS) and the Department of Veterans Affairs (VA) covered all 59 drugs from the FDA license date, delays were evident for some Regence Group decisions that were informed by cost effectiveness (median, 0 days; semi-interquartile range [SIQR], 122 days; n = 22). Relative to the European Medicines Agency license date, median time to coverage was 783 days (SIQR, 170 days) for NICE and 231 days (SIQR, 129 days) for the SMC. CONCLUSION: Anticancer drug coverage decisions that consider cost effectiveness are associated with greater restrictions and slower time to coverage. However, this approach may represent an explicit alternative to rationing achieved through the use of patient copayments.\",\n          \"The p73 gene is less involved in the development but involved in the progression of neuroblastoma.We performed expression, mutation, loss of heterozygosity (LOH) and fluorescence in situ hybridization (FISH) analyses of the p73 gene in neuroblastomas (<e>NBs</e>). Reverse transcription-polymerase chain reaction (RT-PCR) using primers which can detect both the p73alpha and p73beta transcripts was performed on 30 fresh NBs and 22 NB cell lines. Aberrant expression of the p73 gene was found in 4 (25%) of 16 primary tumors found by mass screening and in 10 (71.4%) of 14 primary tumors found clinically. The rates of expression in these two types of tumors were significantly different (p=0.026, Fisher's exact test). The incidence of aberrant expression of the p73 gene was significantly higher in stage IV patients than in stages I, II, III plus IVS patients (p=0.0236, Fisher's exact test). No homozygous deletions or rearrangements of the p73 gene were found in any samples examined. In addition to the polymorphism in exon 2, a silent mutation (codon 336 GCC/GCT) was found in one primary tumor. LOH of the p73 gene was detected in 5 (15%) of 33 primary NBs using PCR-LOH analysis. FISH analysis showed that all 17 NB cell lines used in this study revealed allelic loss of the p73 gene, while most of them expressed the p73 gene. These results suggest that the p73 gene is not monoallelically expressed in NB. We conclude that the p73 gene is less involved in the development but involved in the progression of neuroblastoma.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ABBREV\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 227,\n        \"samples\": [\n          \"synapsis\",\n          \"br\",\n          \"labors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ABBREV_CUI\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 162,\n        \"samples\": [\n          \"['C0040395', 'C0040405']\",\n          \"['C0022925', 'C0006147']\",\n          \"['C0032241', 'C0026934']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abbrev_cui_semantic_types\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 145,\n        \"samples\": [\n          \"[['Diagnostic Procedure'], ['Gene or Genome'], ['Amino Acid, Peptide, or Protein', 'Biologically Active Substance']]\",\n          \"[['Geographic Area'], ['Nucleic Acid, Nucleoside, or Nucleotide', 'Biologically Active Substance']]\",\n          \"[['Professional Society'], ['Amino Acid, Peptide, or Protein', 'Enzyme']]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abbrev_cui_relations\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 162,\n        \"samples\": [\n          \"[[('method_of', 'Multidirectional X-ray tomography'), ('method_of', 'Optical coherence tomography of eye region'), ('isa', 'Radiographic imaging procedure'), ('method_of', 'Optical coherence tomography of retina'), ('method_of', 'Integrated optical coherence tomography and scanning laser ophthalmoscopy'), ('inverse_isa', 'Optical coherence tomography'), ('method_of', 'Optical coherence tomography'), ('method_of', 'Tomography - chest'), ('inverse_isa', 'Tomography - chest'), ('isa', 'Plain X-ray imaging - action'), ('associated_procedure_of', 'Tomography requested'), ('is_interpreted_by', 'Tomography normal'), ('is_interpreted_by', 'Tomography abnormal'), ('method_of', 'Tomography - gallbladder'), ('inverse_isa', 'Tomography - gallbladder'), ('inverse_isa', 'Tomography - larynx/trachea'), ('inverse_isa', 'Tomography - head/neck'), ('method_of', 'Tomography - head/neck'), ('inverse_isa', 'Tomography - skeleton/limbs'), ('method_of', 'Tomography - skeleton/limbs'), ('method_of', 'Tomography - larynx/trachea'), ('isa', 'Radiographic imaging - action'), ('method_of', 'Polytomography'), ('inverse_isa', 'Polytomography'), ('method_of', 'Cardiac tomography')], [('inverse_isa', 'Radionuclide imaging with computed tomography attenuation correction'), ('inverse_isa', 'Forensic computed tomography'), ('inverse_isa', 'CT of small intestine'), ('inverse_isa', 'Computed tomography for radiotherapy planning'), ('inverse_isa', 'Computed tomography with maximum intensity projection'), ('inverse_isa', 'Cone beam CT'), ('isa', 'Radiographic imaging procedure'), ('inverse_isa', 'Positron emission tomography with computed tomography'), ('inverse_isa', 'CT of urinary tract'), ('inverse_isa', 'Virtual CT bronchoscopy'), ('possibly_equivalent_to', 'CT of site'), ('inverse_isa', 'CT special views and positions'), ('inverse_isa', 'CT without contrast'), ('inverse_isa', 'Spiral computed tomography scan'), ('inverse_isa', 'CT with contrast'), ('has_method', 'Computed tomography imaging - action'), ('inverse_isa', 'CT, 3 dimensional reconstruction'), ('possibly_equivalent_to', 'CT of regions'), ('possibly_equivalent_to', 'CT of systems'), ('inverse_isa', 'CT of cardiovascular system'), ('inverse_isa', 'CT of limb regions'), ('inverse_isa', 'CT of back region'), ('inverse_isa', 'Special CT studies'), ('inverse_isa', 'CT of nervous system'), ('associated_procedure_of', 'CT requested')]]\",\n          \"[[('is_interpreted_by', 'Polygalactia'), ('isa', 'Breast function')], [('focus_of', 'Dietary education for breast feeding'), ('focus_of', 'Suppression of lactation using hormone'), ('focus_of', 'Assistance with breastfeeding'), ('focus_of', 'Promotion of lactation'), ('focus_of', 'Resting the breast from breastfeeding'), ('focus_of', 'Procedure related to breastfeeding'), ('focus_of', 'Natural suppression of lactation'), ('focus_of', 'Positioning baby at breast'), ('focus_of', 'Encouraging rooting reflex'), ('focus_of', 'Initiation of breastfeeding'), ('possibly_equivalent_to', 'Breastfeeding (mother)'), ('possibly_equivalent_to', 'Breastfeeding (infant)'), ('focus_of', 'Breastfeeding support education'), ('focus_of', 'Breastfeeding support assessment'), ('focus_of', 'Breast feeding support management'), ('isa', 'Infant feeding method - finding'), ('focus_of', 'Breastfeeding support'), ('inverse_isa', 'Bottle changed to breast'), ('inverse_isa', 'Demand fed'), ('focus_of', 'Inhibition of lactation procedure'), ('inverse_isa', 'Breastfeeding stopped'), ('inverse_isa', 'Breastfeeding with supplement'), ('interprets', 'Infant feeding method'), ('inverse_isa', 'Breastfeeding started'), ('associated_finding_of', 'H/O: infant breast fed')]]\",\n          \"[[('isa', 'Infective pleurisy'), ('has_pathological_process', 'Infectious process'), ('has_pathological_process', 'Infectious process'), ('has_pathological_process', 'Infectious process'), ('has_finding_site', 'Structure of parenchyma of lung'), ('has_finding_site', 'Bronchial structure'), ('mapped_to', 'Bronchopneumonia, unspecified organism'), ('mapped_to', 'Bronchopneumonia, unspecified'), ('isa', 'Bronchopneumonia'), ('has_finding_site', 'Pleural structure'), ('has_associated_morphology', 'Inflammation and consolidation'), ('has_associated_morphology', 'Inflammation and consolidation'), ('has_associated_morphology', 'Inflammation and consolidation')], [('causative_agent_of', 'Seal finger'), ('isa', 'Prokaryote-cell wall absent'), ('causative_agent_of', 'Mycoplasmal anemia'), ('inverse_isa', 'Mycoplasma species, not Mycoplasma pneumoniae'), ('inverse_isa', 'Mycoplasma coccoides'), ('inverse_isa', 'Mycoplasma testudineum'), ('component_of', 'Respiratory Mycoplasma species, culture'), ('component_of', 'Genital Mycoplasma species, culture'), ('replaces', 'Haemobartonella species'), ('replaces', 'Mycoplasma species positive'), ('replaces', 'Mycoplasma species and ureaplasma positive'), ('possibly_equivalent_to', 'Mycoplasma species'), ('inverse_isa', 'Mycoplasma phocarinis'), ('inverse_isa', 'Mycoplasma oxoniensis'), ('inverse_isa', 'Mycoplasma buteonis'), ('inverse_isa', 'Mycoplasma lagogenitalium'), ('inverse_isa', 'Mycoplasma imitans'), ('inverse_isa', 'Mycoplasma agassizii'), ('inverse_isa', 'Mycoplasma felifaucium'), ('inverse_isa', 'Mycoplasma leonicaptivi'), ('inverse_isa', 'Mycoplasma leopharyngis'), ('inverse_isa', 'Mycoplasma microti'), ('inverse_isa', 'Mycoplasma sturni'), ('inverse_isa', 'Mycoplasma alligatoris'), ('inverse_isa', 'Mycoplasma adleri')]]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL_CUI\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 336,\n        \"samples\": [\n          \"C0014792\",\n          \"C0006767\",\n          \"C0258432\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LABEL_ENCODING\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 0,\n        \"max\": 73,\n        \"num_unique_values\": 67,\n        \"samples\": [\n          65,\n          70,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GOLD_CUI_semantic_types\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 67,\n        \"samples\": [\n          \"Biologically Active Substance\",\n          \"Body Substance\",\n          \"Organism Function\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import torch\n",
        "import requests\n",
        "import csv\n",
        "import os\n",
        "\n",
        "df = pd.read_csv(\"./data/data.csv\")\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cache UMLS results to avoid repeated API calls\n",
        "CACHE_FILE = \"semantic_cash.csv\"\n",
        "\n",
        "# Load the cache from the CSV file if it exists\n",
        "cuis_cache = {}\n",
        "if os.path.exists(CACHE_FILE):\n",
        "    with open(CACHE_FILE, 'r', encoding='utf-8') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "        next(csv_reader, None)  # Skip header row\n",
        "        for row in csv_reader:\n",
        "            if len(row) == 3:  # Avoids errors when rows have missing values\n",
        "                cui, semantic_types_str, relations_str = row\n",
        "                cuis_cache[cui] = (ast.literal_eval(semantic_types_str), ast.literal_eval(relations_str))\n",
        "\n",
        "\n",
        "def save_cache_to_csv(cache, filename):\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow([\"cui\", \"semantic_types\", \"relations\"])  # Write header\n",
        "        for cui, (semantic_types, relations) in cache.items():\n",
        "            csv_writer.writerow([cui, str(semantic_types), str(relations)])\n",
        "\n",
        "\n",
        "\n",
        "def extract_relation_info(relation_data):\n",
        "    \"\"\"\n",
        "    Extracts additionalRelationLabel, relatedId, and relatedIdName from UMLS relation data.\n",
        "\n",
        "    Args:\n",
        "      relation_data: A list of UMLS relation dictionaries\n",
        "\n",
        "    Returns:\n",
        "        A list of tuples, each containing (additionalRelationLabel, relatedId, relatedIdName)\n",
        "    \"\"\"\n",
        "\n",
        "    extracted_relations = []\n",
        "    for relation in relation_data:\n",
        "        try:\n",
        "            relation_label = relation.get(\"additionalRelationLabel\", None)\n",
        "            related_id_name = relation.get(\"relatedIdName\", None)\n",
        "\n",
        "            if \"additionalRelationLabel\" in relation and relation['additionalRelationLabel'] in [\"STY\", \"isa\",\"possibly_equivalent_to\",\"component_of\",'inverse_isa','replaces','replaced_by' ]:\n",
        "                 extracted_relations.append((relation_label, related_id_name)) # Extract the 2 values\n",
        "        except (KeyError, TypeError) as e:\n",
        "            print(f\"Warning: Error extracting relations details. Error: {e}\")\n",
        "            continue #Skip bad entries.\n",
        "    return extracted_relations\n",
        "\n",
        "\n",
        "def get_hierarchical_semantic_types(cui):\n",
        "    \"\"\"\n",
        "    Searches for concepts in UMLS Metathesaurus, using a cache to avoid redundant API calls.\n",
        "    \"\"\"\n",
        "    semantic_types_names = []\n",
        "    try:\n",
        "        response = requests.get(\n",
        "           f\"{UMLS_API_URL}/content/2024AB/CUI/{cui}/\",\n",
        "            params={\n",
        "               \"apiKey\": UMLS_API_KEY,\n",
        "               \"sabs\": \"SNOMEDCT_US\" # or other specific source\n",
        "                },\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        semantic_relations = set()\n",
        "\n",
        "\n",
        "        if 'result' in data and 'semanticTypes' in data['result']:\n",
        "            if data['result']['semanticTypes']:\n",
        "                semantic_types_names = [sty[\"name\"] for sty in data[\"result\"][\"semanticTypes\"]]\n",
        "\n",
        "\n",
        "                try:\n",
        "                      response2 = requests.get(\n",
        "                          f\"{UMLS_API_URL}/content/2024AB/CUI/{cui}/relations\",\n",
        "                          params={\n",
        "                            \"apiKey\": UMLS_API_KEY,\n",
        "                             \"sabs\": \"SNOMEDCT_US\" # or other specific source\n",
        "                              },\n",
        "                        )\n",
        "                      response2.raise_for_status()\n",
        "                      data2 = response2.json()\n",
        "                      if \"result\" in data2 and isinstance(data2['result'], list):\n",
        "                           semantic_relations = extract_relation_info(data2['result']) # call function to extract related info\n",
        "\n",
        "                      else:\n",
        "                           print(f\"Warning: No relations returned for '{cui}'\")\n",
        "\n",
        "\n",
        "                except requests.exceptions.RequestException as e:\n",
        "                      print(f\"Error searching UMLS for CUI relations '{cui}': {e}\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                 semantic_types_names = None\n",
        "                 semantic_relations = None\n",
        "\n",
        "        return  semantic_types_names ,list(semantic_relations)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error searching UMLS for CUI Semantic_types'{cui}': {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def add_semantic_types_column(df):\n",
        "    \"\"\"\n",
        "    Adds \"ABBREV_semantic_types\" and \"ABBREV_relations\"columns to all cuis in the ABBREV column in the DataFrame\n",
        "    based on the existing 'ABBREV' columns.\n",
        "    \"\"\"\n",
        "\n",
        "    def get_concept_st(row):\n",
        "        abbrev = row['ABBREV_CUI']\n",
        "        semantic_types = []\n",
        "        relations = []\n",
        "\n",
        "        abbrev_cui_relations = []\n",
        "        abbrev_cui_semantic_types = []\n",
        "\n",
        "        for cui in ast.literal_eval(abbrev) if pd.notna(abbrev) else []:\n",
        "            if cui and isinstance(cui, str):\n",
        "                if cui in cuis_cache:\n",
        "                    abbrev_cui_semantic_types, abbrev_cui_relations = cuis_cache[cui]\n",
        "\n",
        "                else:\n",
        "                    result = get_hierarchical_semantic_types(cui)\n",
        "                    if result:\n",
        "                        abbrev_cui1_semantic_types, abbrev_cui1_relations = result\n",
        "                        cuis_cache[cui] = (abbrev_cui_semantic_types, abbrev_cui_relations)\n",
        "                    else:\n",
        "                        abbrev_cui_semantic_types, abbrev_cui_relations = [], []\n",
        "\n",
        "\n",
        "\n",
        "        return abbrev_cui_semantic_types , abbrev_cui_relations\n",
        "\n",
        "    df[['abbrev_cui_semantic_types', 'abbrev_cui_relations']] = df.apply(get_concept_st, axis=1, result_type='expand')\n",
        "    save_cache_to_csv(cuis_cache, CACHE_FILE)\n",
        "    print(\"Added 'ABBREV_SEMANTIC_TYPES'and 'ABBREV_CUI_RELATIONS'columns to DataFrame successfully.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "Sty_df = add_semantic_types_column(df)\n",
        "\n",
        "# Save the updated dataframe to a new csv file\n",
        "NEW_CSV_FILE_PATH = \"100MeDaL_with_semantic_types_and_Relations.csv\"\n",
        "Sty_df.to_csv(NEW_CSV_FILE_PATH, index=False, encoding='utf-8')\n",
        "print(f\"Saved updated CSV to: {NEW_CSV_FILE_PATH}\")\n",
        "Sty_df.head(100)"
      ],
      "metadata": {
        "id": "_1zBKnCAkY0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding the semantic types and semantic relation of the Abbrev. term and labels**"
      ],
      "metadata": {
        "id": "WiMfCUKqtV3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cache UMLS results to avoid repeated API calls\n",
        "CACHE_FILE = \"semantic_types_&relations_cach.csv\"\n",
        "\n",
        "# Load the cache from the CSV file if it exists\n",
        "cuis_cache = {}\n",
        "if os.path.exists(CACHE_FILE):\n",
        "    with open(CACHE_FILE, 'r', encoding='utf-8') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "        next(csv_reader, None)  # Skip header row\n",
        "        for row in csv_reader:\n",
        "            if len(row) == 3:  # Avoids errors when rows have missing values\n",
        "                cui, semantic_types_str, relations_str = row\n",
        "                cuis_cache[cui] = (ast.literal_eval(semantic_types_str), ast.literal_eval(relations_str))\n",
        "\n",
        "\n",
        "def save_cache_to_csv(cache, filename):\n",
        "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow([\"cui\", \"semantic_types\", \"relations\"])  # Write header\n",
        "        for cui, (semantic_types, relations) in cache.items():\n",
        "            csv_writer.writerow([cui, str(semantic_types), str(relations)])\n",
        "\n",
        "\n",
        "def extract_relation_info(relation_data):\n",
        "    \"\"\"\n",
        "    Extracts additionalRelationLabel, relatedId, and relatedIdName from UMLS relation data.\n",
        "\n",
        "    Args:\n",
        "      relation_data: A list of UMLS relation dictionaries\n",
        "\n",
        "    Returns:\n",
        "        A list of tuples, each containing (additionalRelationLabel, relatedId, relatedIdName)\n",
        "    \"\"\"\n",
        "\n",
        "    extracted_relations = []\n",
        "    for relation in relation_data:\n",
        "        try:\n",
        "            relation_label = relation.get(\"additionalRelationLabel\", None)\n",
        "            related_id_name = relation.get(\"relatedIdName\", None)\n",
        "\n",
        "            if relation_label and related_id_name: # only stores a value if all three exist\n",
        "                 extracted_relations.append((relation_label, related_id_name)) # Extract the 3 values\n",
        "        except (KeyError, TypeError) as e:\n",
        "            print(f\"Warning: Error extracting relations details. Error: {e}\")\n",
        "            continue #Skip bad entries.\n",
        "    return extracted_relations\n",
        "\n",
        "\n",
        "def get_semantic_type(cui):\n",
        "    semantic_types_names = []\n",
        "    semantic_relations = []\n",
        "    if cui in cuis_cache:\n",
        "        semantic_types_names, semantic_relations = cuis_cache[cui]\n",
        "    else:\n",
        "        try:\n",
        "            response = requests.get(\n",
        "              f\"{UMLS_API_URL}/content/2024AB/CUI/{cui}/\",\n",
        "                params={\n",
        "                  \"apiKey\": UMLS_API_KEY,\n",
        "                  \"sabs\": \"SNOMEDCT_US\" # or other specific source\n",
        "                    },\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            #semantic_relations = set()\n",
        "\n",
        "\n",
        "            if 'result' in data and 'semanticTypes' in data['result']:\n",
        "                if data['result']['semanticTypes']:\n",
        "                    semantic_types_names = [sty[\"name\"] for sty in data[\"result\"][\"semanticTypes\"]] #Corrected: Uses all semantic types\n",
        "                  # print(semantic_types_names)\n",
        "                    try:\n",
        "                          response2 = requests.get(\n",
        "                              f\"{UMLS_API_URL}/content/2024AB/CUI/{cui}/relations\",\n",
        "                              params={\n",
        "                                \"apiKey\": UMLS_API_KEY,\n",
        "                                \"sabs\": \"SNOMEDCT_US\" # or other specific source\n",
        "                                  },\n",
        "                            )\n",
        "                          response2.raise_for_status()\n",
        "                          data2 = response2.json()\n",
        "                          if \"result\" in data2 and isinstance(data2['result'], list):\n",
        "                              semantic_relations = extract_relation_info(data2['result']) # call function to extract related info\n",
        "\n",
        "                          else:\n",
        "                              print(f\"Warning: No relations returned for '{cui}'\")\n",
        "                              semantic_relations = []\n",
        "\n",
        "\n",
        "                    except requests.exceptions.RequestException as e:\n",
        "                          #print(f\"Error searching UMLS for CUI relations '{cui}': {e}\")\n",
        "                          semantic_relations = []\n",
        "                else:\n",
        "                  semantic_types_names = []\n",
        "                  semantic_relations = []\n",
        "\n",
        "            else:\n",
        "              semantic_types_names = [] #return empty list\n",
        "              semantic_relations = [] #return empty list\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error searching UMLS for CUI Semantic_types'{cui}': {e}\")\n",
        "            semantic_types_names = [] #return empty list\n",
        "            semantic_relations = [] #return empty list\n",
        "\n",
        "    cuis_cache[cui] = semantic_types_names, list(semantic_relations)\n",
        "    return  semantic_types_names ,list(semantic_relations) # Always return a tuple\n",
        "\n",
        "def add_semantic_types_column(df):\n",
        "    \"\"\"\n",
        "    Adds \"ABBREV_semantic_types\" and \"ABBREV_relations\"columns to all cuis in the ABBREV column in the DataFrame\n",
        "    based on the existing 'ABBREV' columns.\n",
        "    \"\"\"\n",
        "\n",
        "    def get_concept_st(row):\n",
        "        abbrev = row['ABBREV_CUI']\n",
        "        #semantic_types = []\n",
        "        #relations = []\n",
        "\n",
        "        abbrev_cui_relations = []\n",
        "        abbrev_cui_semantic_types = []\n",
        "\n",
        "        for cui in ast.literal_eval(abbrev) if pd.notna(abbrev) else []:\n",
        "            if cui and isinstance(cui, str):\n",
        "                if cui in cuis_cache:\n",
        "                    abbrev_cui_semantic_types, abbrev_cui_relations = cuis_cache[cui]\n",
        "                    #print(\"Retrieved from cache\", cui)\n",
        "                else:\n",
        "\n",
        "                    result = get_semantic_type(cui)\n",
        "                    if result:\n",
        "                        abbrev_cui_semantic_types, abbrev_cui_relations = result\n",
        "                        #cuis_cache[cui] = (abbrev_cui_semantic_types, abbrev_cui_relations)\n",
        "                    else:\n",
        "                        abbrev_cui_semantic_types, abbrev_cui_relations = [], []\n",
        "\n",
        "        return abbrev_cui_semantic_types , abbrev_cui_relations\n",
        "\n",
        "\n",
        "    df[['abbrev_cui_semantic_types', 'abbrev_cui_relations']] = df.apply(get_concept_st, axis=1, result_type='expand')\n",
        "\n",
        "    save_cache_to_csv(cuis_cache, CACHE_FILE)\n",
        "    print(\"Added 'ABBREV_SEMANTIC_TYPES'and 'ABBREV_CUI_RELATIONS'columns to DataFrame successfully.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def add_gold_standard_semantic_info(df):\n",
        "    \"\"\"\n",
        "    Adds 'GOLD_CUI_semantic_types' and 'GOLD_CUI_relations' columns to the DataFrame\n",
        "    based on the existing 'GOLD_CUI' column.\n",
        "    \"\"\"\n",
        "    def get_gold_concept_info(row):\n",
        "        cui = row['LABEL_CUI']\n",
        "        #cui = gold_cui[0]\n",
        "        #semantic_types = []\n",
        "        relations = []\n",
        "\n",
        "        gold_cui_relations = []\n",
        "        gold_cui_semantic_types = []\n",
        "\n",
        "        #for cui in ast.literal_eval(gold_cui) if pd.notna(gold_cui) else []: # and gold_cui.startswith('[')\n",
        "        #print(cui)\n",
        "        if cui and isinstance(cui, str):\n",
        "            if cui in cuis_cache:\n",
        "                gold_cui_semantic_types, gold_cui_relations = cuis_cache[cui]\n",
        "                #print(\"Retrieved from cache\", cui)\n",
        "            else:\n",
        "\n",
        "                result = get_semantic_type(cui)\n",
        "                if result:\n",
        "                    gold_cui_semantic_types, gold_cui_relations = result\n",
        "                    cuis_cache[cui] = (gold_cui_semantic_types, gold_cui_relations)\n",
        "                else:\n",
        "                    gold_cui_semantic_types, gold_cui_relations = [], []\n",
        "        return pd.Series({'GOLD_CUI_relations': gold_cui_relations})\n",
        "\n",
        "\n",
        "    df['GOLD_CUI_relations'] = df.apply(get_gold_concept_info, axis=1, result_type='expand')\n",
        "\n",
        "    save_cache_to_csv(cuis_cache, CACHE_FILE) # Save cache to csv\n",
        "    print(\"Added 'GOLD_CUI_relations' column successfully.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "#Sty_df.head(100)\n",
        "\n",
        "#All_Sty_df = add_semantic_types_column(df)\n",
        "All_Sty_Gold_df = add_gold_standard_semantic_info(df)\n",
        "\n",
        "# Save the updated dataframe to a new csv file\n",
        "NEW_CSV_FILE_PATH = \"MSH_All_dataset_with_GoldRelations.csv\"\n",
        "All_Sty_Gold_df.to_csv(NEW_CSV_FILE_PATH, index=False, encoding='utf-8')\n",
        "print(f\"Saved updated CSV to: {NEW_CSV_FILE_PATH}\")\n",
        "\n",
        "#save cache to file\n",
        "#save_cache_to_csv(cuis_cache, CACHE_FILE)\n",
        "'''\n",
        "# Save the updated dataframe to a new csv file\n",
        "NEW_CSV_FILE_PATH2 = \"100MeDaL_with_all_semantic_types_and_Relations__for_abbrev_label.csv\"\n",
        "All_Sty_Gold_df.to_csv(NEW_CSV_FILE_PATH2, index=False, encoding='utf-8')\n",
        "print(f\"Saved updated CSV to: {NEW_CSV_FILE_PATH2}\")\n",
        "'''\n",
        "All_Sty_Gold_df.head(100)"
      ],
      "metadata": {
        "id": "rMdHZEjXmnSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filter sparce abbreviations**"
      ],
      "metadata": {
        "id": "ZMHvl5QN3VPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filter data fram_e with necessary values\n",
        "df = pd.read_csv(\"./data/data.csv\")\n",
        "print(df.shape)\n",
        "min_abbrev_example_count = 20\n",
        "min_semantic_type_count = 20\n",
        "min_label_semantic_type_count = 50\n",
        "\n",
        "def filter_dataframe(df, min_abbrev_example_count, min_semantic_type_count, min_gold_semantic_type_count):\n",
        "    \"\"\"Filters the DataFrame based on the number of labels per abbreviation, and semantic types per (abbreviation, semantic type) pair.\"\"\"\n",
        "\n",
        "    # Filter by abbreviation count\n",
        "    abbrev_counts = df['ABBREV'].value_counts()\n",
        "    filtered_abbrevs = abbrev_counts[abbrev_counts >= min_abbrev_example_count].index\n",
        "    filtered_df = df[df['ABBREV'].isin(filtered_abbrevs)]\n",
        "\n",
        "    # Filter by GOLD_CUI_semantic_types count\n",
        "    value_counts = filtered_df['GOLD_CUI_semantic_types'].value_counts()\n",
        "    filtered_semantic_types = value_counts[value_counts >= min_gold_semantic_type_count].index\n",
        "    filtered_df = filtered_df[filtered_df['GOLD_CUI_semantic_types'].isin(filtered_semantic_types)]\n",
        "\n",
        "    # Group by abbreviation and gold semantic types, then filter\n",
        "    grouped_data = filtered_df.groupby(['ABBREV', filtered_df['GOLD_CUI_semantic_types'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)]).size().reset_index(name='count')\n",
        "    filtered_abbrevs_semantic = grouped_data[grouped_data['count'] <= min_semantic_type_count]\n",
        "    print(filtered_abbrevs_semantic)\n",
        "    abbrev_semantic_dict = {}\n",
        "\n",
        "    for i, row in filtered_abbrevs_semantic.iterrows():\n",
        "      semantic_types =[]\n",
        "      if row['ABBREV'] in abbrev_semantic_dict:\n",
        "        semantic_types = abbrev_semantic_dict[row['ABBREV']]\n",
        "        semantic_types.append(row['GOLD_CUI_semantic_types'])\n",
        "        abbrev_semantic_dict[row['ABBREV']] = semantic_types\n",
        "      else:\n",
        "        abbrev_semantic_dict[row['ABBREV']] = [row['GOLD_CUI_semantic_types']]\n",
        "\n",
        "    for i, row in filtered_df.iterrows():\n",
        "        if row['ABBREV'] in abbrev_semantic_dict:\n",
        "           # print(row['ABBREV'], \",\", row['GOLD_CUI_semantic_types'])\n",
        "            #filtered_df.drop(i, inplace=True)\n",
        "            if row['GOLD_CUI_semantic_types'][0] in abbrev_semantic_dict[row['ABBREV']]:\n",
        "                #print(row['ABBREV'], \",\", row['GOLD_CUI_semantic_types'])\n",
        "                filtered_df.drop(i, inplace=True)\n",
        "\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    #print(filtered_abbrevs_semantic)\n",
        "\n",
        "    print(\"Filtered Semantic Abbrevs:\")\n",
        "    print(len(filtered_abbrevs_semantic))\n",
        "    return filtered_df\n",
        "\n",
        "# Filter DataFrame\n",
        "filtered_df = filter_dataframe(df, min_abbrev_example_count, min_semantic_type_count, min_label_semantic_type_count)\n",
        "filtered_df.to_csv(\"MSH_All_dataset_with_GoldRelations_filtered.csv\", index=False)\n",
        "print(\"Filtered DataFrame saved to '100filtered_Medal.csv'\")\n",
        "print(\"Shape:\",filtered_df.shape)\n",
        "#filtered_df.head(100)"
      ],
      "metadata": {
        "id": "6kvtCq093bzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.groupby(['ABBREV', filtered_df['GOLD_CUI_semantic_types'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None)]).size().reset_index(name='count')"
      ],
      "metadata": {
        "id": "4X9JHoo97bjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropping unnecessary columns**"
      ],
      "metadata": {
        "id": "exbKB-A2qRQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unneeded columns\n",
        "def drop_columns(df):\n",
        "    columns_to_drop = ['abbrev_uri', 'label_uri'] # add columns to drop\n",
        "    df = df.drop(columns=columns_to_drop, errors='ignore')  # errors = 'ignore' prevents errors if a column is already dropped\n",
        "    return df\n",
        "\n",
        "filtered_df = drop_columns(filtered_df)\n",
        "\n",
        "\n",
        "print(\"Filtered DataFrame with semantic groups added to relations, and unnecessary columns dropped:\")\n",
        "filtered_df.to_csv(\"100MeDaL_with_all_semantic_features_filtered_columns_last.csv\", index=False)\n",
        "print(\"DataFrame with context features added\")\n",
        "print(filtered_df.head())"
      ],
      "metadata": {
        "id": "YArq4Z7oqVsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unneeded columns\n",
        "def drop_columns(df):\n",
        "    columns_to_drop = ['GOLD_CUI_relations', 'context_relations'] # add columns to drop\n",
        "    df = df.drop(columns=columns_to_drop, errors='ignore')  # errors = 'ignore' prevents errors if a column is already dropped\n",
        "    return df\n",
        "\n",
        "filtered_df = drop_columns(filtered_df)\n",
        "\n",
        "\n",
        "print(\"Filtered DataFrame with semantic groups added to relations, and unnecessary columns dropped:\")\n",
        "filtered_df.to_csv(\"100MeDaL_with_all_semantic_features_filtered_columns_last.csv\", index=False)\n",
        "print(\"DataFrame with context features added\")\n",
        "print(filtered_df.head())"
      ],
      "metadata": {
        "id": "pXw62Bc5seRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding semantic group info**"
      ],
      "metadata": {
        "id": "_su0aUp4qWo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_semantic_groups(file_path=\"SemGroups_2018.txt\"):\n",
        "    \"\"\"Loads semantic groups from a text file into a dictionary.\"\"\"\n",
        "    semantic_groups = defaultdict(list)\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\"|\")\n",
        "            if len(parts) == 4:\n",
        "                _, group,  _ ,stype = parts # get the group and the semantic type\n",
        "                semantic_groups[stype].append(group) # assign the group as a list of related semantic types\n",
        "    return semantic_groups\n",
        "\n",
        "semantic_groups = load_semantic_groups()\n",
        "print(\"Semantic Groups Loaded!\")\n",
        "print(semantic_groups)"
      ],
      "metadata": {
        "id": "rcwXTQH6rN-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "g_uytm6swOut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "def add_semantic_group_to_relations(df, semantic_groups):\n",
        "    \"\"\"Adds semantic group information to the relation columns.\"\"\"\n",
        "    augmented_relations_all_abbrev = []\n",
        "    augmented_relations_all_context = []\n",
        "    augmented_relations_all_gold = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "\n",
        "        abbrev_cui_semantic_types = ast.literal_eval(row['abbrev_cui_semantic_types']) #if isinstance(row[\"abbrev_cui_semantic_types\"], str) and row[\"abbrev_cui_semantic_types\"] != 'nan' else []\n",
        "         # Check if 'context_semantic_types' is a string and try to convert it to a list\n",
        "        ''' if isinstance(row[\"context_semantic_types\"], str):\n",
        "            try:\n",
        "                context_semantic_types = ast.literal_eval(row[\"context_semantic_types\"])\n",
        "            except (SyntaxError, ValueError):\n",
        "                # If conversion fails, try to extract values assuming a specific format\n",
        "                # For example, if the string looks like \"[['value1'], ['value2']]\", you can use:\n",
        "                context_semantic_types = [item.strip(\"[']\") for item in row[\"context_semantic_types\"][1:-1].split(\"', '\")]\n",
        "\n",
        "        else:\n",
        "            context_semantic_types = row[\"context_semantic_types\"] if isinstance(row[\"context_semantic_types\"], list) else []\n",
        "        '''\n",
        "        context_semantic_types = ast.literal_eval(row[\"context_semantic_types\"]) if isinstance(row[\"context_semantic_types\"], str) and row[\"context_semantic_types\"] != 'nan' else []\n",
        "        #context_semantic_types = ast.literal_eval(row[\"context_semantic_types\"]) #if isinstance(row[\"context_semantic_types\"], str) and row[\"context_semantic_types\"] != 'nan' else []\n",
        "        #gold_semantic_types = ast.literal_eval(row['GOLD_CUI_semantic_types']) if pd.notna(row['GOLD_CUI_semantic_types']) else [] # get semantic types from the CUI\n",
        "        gold_semantic_types = ast.literal_eval(row[\"GOLD_CUI_semantic_types\"]) # if isinstance(row[\"GOLD_CUI_semantic_types\"], str) and row[\"GOLD_CUI_semantic_types\"] != 'nan' else []\n",
        "\n",
        "        abbrev_relations = ast.literal_eval(row['abbrev_cui_relations']) #if pd.notna(row['abbrev_cui_relations']) else []\n",
        "        context_relations = row[\"context_relations\"] #if isinstance(row[\"context_relations\"], str) and row[\"context_semantic_types\"] != 'nan' else []\n",
        "        gold_relations = row['GOLD_CUI_relations']\n",
        "\n",
        "        # Add semantic group to abbrev relations\n",
        "        augmented_relations_abbrev = []\n",
        "\n",
        "         # Iterate through the list of semantic types\n",
        "        for semantic_type in abbrev_cui_semantic_types:\n",
        "          if semantic_type and isinstance(semantic_type, str) and semantic_type in semantic_groups:\n",
        "              #print(semantic_type)\n",
        "              for group in semantic_groups[semantic_type]:\n",
        "                  augmented_relations_abbrev.append(( 'semantic_group',group))\n",
        "\n",
        "          else:\n",
        "              for i, semantic_type in enumerate(abbrev_cui_semantic_types):\n",
        "                  if semantic_type:\n",
        "                    for st in semantic_type:\n",
        "                      # Check if the semantic type is a string and in semantic_groups\n",
        "                      if isinstance(st, str) and st in semantic_groups:\n",
        "                            for group in semantic_groups[st]:\n",
        "                                augmented_relations_abbrev.append(('semantic_group', group))\n",
        "\n",
        "        '''\n",
        "        for semantic_type_list in abbrev_cui_semantic_types:\n",
        "           # Iterate through each semantic type in the list\n",
        "           for semantic_type in semantic_type_list:\n",
        "              # Check if the semantic type is a string and in semantic_groups\n",
        "              if isinstance(semantic_type, str) and semantic_type in semantic_groups:\n",
        "                   for group in semantic_groups[semantic_type]:\n",
        "                       augmented_relations_abbrev.append(('semantic_group', group))\n",
        "        '''\n",
        "        for i, relation in enumerate(abbrev_relations):\n",
        "          if relation:# and isinstance(relation, list): # handle if the relations are an empty list or missing\n",
        "             if isinstance(relation, (list, tuple)) and len(relation) >= 2:\n",
        "                r, related_concept = relation[:2]  # Unpack only the first 2 elements\n",
        "                augmented_relations_abbrev.append((r, related_concept))\n",
        "             else:\n",
        "                for r, related_concept in relation:\n",
        "                    augmented_relations_abbrev.append((r,related_concept))\n",
        "                    # Iterate through the list of semantic types\n",
        "                    for st in related_concept:\n",
        "                      # Check if the semantic type is a string and in semantic_groups\n",
        "                      if isinstance(st, str) and st in semantic_groups:\n",
        "                            for group in semantic_groups[st]:\n",
        "                                augmented_relations_abbrev.append(('semantic_group', group))\n",
        "\n",
        "                '''\n",
        "                    if related_concept in semantic_groups:\n",
        "                      for group in semantic_groups[related_concept]:\n",
        "                            augmented_relations_abbrev.append(('semantic_group', group))\n",
        "        for i, semantic_type in enumerate(abbrev_cui_semantic_types):\n",
        "           if semantic_type and semantic_type in semantic_groups:\n",
        "             for group in semantic_groups[semantic_type]:\n",
        "                #print(group)\n",
        "                augmented_relations_abbrev.append(( 'semantic_group',group))\n",
        "        '''\n",
        "        # Add semantic group to context relations\n",
        "        augmented_relations_context = []\n",
        "        for semantic_type in context_semantic_types:\n",
        "            if semantic_type and isinstance(semantic_type, str) and semantic_type in semantic_groups:\n",
        "                #print(semantic_type)\n",
        "                for group in semantic_groups[semantic_type]:\n",
        "                   augmented_relations_context.append(( 'semantic_group',group))\n",
        "\n",
        "            else:\n",
        "                for i, semantic_type in enumerate(context_semantic_types):\n",
        "                   if semantic_type:\n",
        "                    for st in semantic_type:\n",
        "                      # Check if the semantic type is a string and in semantic_groups\n",
        "                      if isinstance(st, str) and st in semantic_groups:\n",
        "                            for group in semantic_groups[st]:\n",
        "                                augmented_relations_context.append(('semantic_group', group))\n",
        "\n",
        "        if context_relations:\n",
        "          # Check if context_relations is a string representation of a list and convert it\n",
        "          if isinstance(context_relations, str):\n",
        "              try:\n",
        "                  context_relations = ast.literal_eval(context_relations)\n",
        "              except (SyntaxError, ValueError):\n",
        "                  print(f\"Warning: Could not parse context_relations for row {index}: {context_relations}\")\n",
        "                  context_relations = []  # Or handle it differently based on your data\n",
        "          for relation_list in context_relations:\n",
        "            # If relation_list is not iterable (e.g., a single value), skip it\n",
        "             if not isinstance(relation_list, (list, tuple)):\n",
        "                print(f\"Warning: Skipping invalid relation_list in row {index}: {relation_list}\")\n",
        "                continue\n",
        "                # If relation_list has only one element, treat it as the related_concept\n",
        "                if len(relation_list) == 1:\n",
        "                    relation = \"related_to\"  # Or any suitable default relation\n",
        "                    related_concept = relation_list[0]\n",
        "                # If relation_list has two elements, unpack them as relation and related_concept\n",
        "                elif len(relation_list) >= 2:\n",
        "                    relation, related_concept = relation_list[:2] # Unpack the first 2\n",
        "\n",
        "                else:\n",
        "                   for relation, related_concept in relation_list:\n",
        "                        augmented_relations_context.append((relation, related_concept))\n",
        "\n",
        "        # Add semantic group to gold relations\n",
        "        augmented_relations_gold = []\n",
        "        if gold_semantic_types:\n",
        "         for semantic_type in gold_semantic_types:\n",
        "              if semantic_type in semantic_groups:\n",
        "                  for group in semantic_groups[semantic_type]:\n",
        "                    augmented_relations_gold.append((\"semantic_group\", group))\n",
        "\n",
        "        if gold_relations:\n",
        "\n",
        "        # Check if gold_relations is a string representation of a list and convert it\n",
        "          if isinstance(gold_relations, str):\n",
        "              try:\n",
        "                  gold_relations = ast.literal_eval(gold_relations)\n",
        "              except (SyntaxError, ValueError):\n",
        "                  print(f\"Warning: Could not parse gold_relations for row {index}: {gold_relations}\")\n",
        "                  gold_relations = []  # Or handle it differently based on your data\n",
        "          for relation_list in gold_relations:\n",
        "            # If relation_list is not iterable (e.g., a single value), skip it\n",
        "             if not isinstance(relation_list, (list, tuple)):\n",
        "                print(f\"Warning: Skipping invalid relation_list in row {index}: {relation_list}\")\n",
        "                continue\n",
        "                # If relation_list has only one element, treat it as the related_concept\n",
        "                if len(relation_list) == 1:\n",
        "                    relation = \"related_to\"  # Or any suitable default relation\n",
        "                    related_concept = relation_list[0]\n",
        "                # If relation_list has two elements, unpack them as relation and related_concept\n",
        "                elif len(relation_list) >= 2:\n",
        "                    relation, related_concept = relation_list[:2] # Unpack the first 2\n",
        "\n",
        "                else:\n",
        "                   for relation, related_concept in relation_list:\n",
        "                        augmented_relations_gold.append((relation, related_concept))\n",
        "\n",
        "        augmented_relations_all_abbrev.append(augmented_relations_abbrev)\n",
        "        augmented_relations_all_context.append(augmented_relations_context)\n",
        "        augmented_relations_all_gold.append(augmented_relations_gold)\n",
        "\n",
        "    df[\"abbrev_relations\"] = augmented_relations_all_abbrev\n",
        "    df[\"context_relations\"] = augmented_relations_all_context\n",
        "    df[\"gold_relations\"] = augmented_relations_all_gold\n",
        "    return df\n",
        "\n",
        "# Add semantic groups to relations\n",
        "filtered_df = add_semantic_group_to_relations(df, semantic_groups)\n",
        "print(\"Filtered DataFrame with context features and semantic group relations added:\")\n",
        "# Save dataframe with labels\n",
        "filtered_df.to_csv(\"MSH_All_dataset_with_GoldRelations_withcontext_SGroup.csv\", index=False)\n",
        "filtered_df.head(20)\n"
      ],
      "metadata": {
        "id": "3VP1D2s7qcD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import ast\n",
        "def add_semantic_group_to_relations(df, semantic_groups):\n",
        "    \"\"\"Adds semantic group information to the relation columns.\"\"\"\n",
        "    augmented_relations_all_abbrev = []\n",
        "    augmented_relations_all_context = []\n",
        "    augmented_relations_all_gold = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "\n",
        "        abbrev_cui_semantic_types = ast.literal_eval(row['abbrev_cui_semantic_types']) if isinstance(row[\"abbrev_cui_semantic_types\"], str) and row[\"abbrev_cui_semantic_types\"] != 'nan' else []\n",
        "        context_semantic_types = ast.literal_eval(row[\"context_semantic_types\"]) if isinstance(row[\"context_semantic_types\"], str) and row[\"context_semantic_types\"] != 'nan' else []\n",
        "        gold_semantic_types = row[\"GOLD_CUI_semantic_types\"]# if isinstance(row[\"GOLD_CUI_semantic_types\"], str) and row[\"GOLD_CUI_semantic_types\"] != 'nan' else []\n",
        "\n",
        "        abbrev_relations = ast.literal_eval(row['abbrev_cui_relations']) if isinstance(row['abbrev_cui_relations'], str) and row['abbrev_cui_relations'] != 'nan' else []\n",
        "        context_relations = row[\"context_relations\"] if isinstance(row[\"context_relations\"], str) and row[\"context_relations\"] != 'nan' else []\n",
        "        gold_relations = row['GOLD_CUI_relations'] if isinstance(row['GOLD_CUI_relations'], str) and row['GOLD_CUI_relations'] != 'nan' else []\n",
        "\n",
        "\n",
        "        # Add semantic group to abbrev relations\n",
        "        augmented_relations_abbrev = []\n",
        "\n",
        "        for semantic_type in abbrev_cui_semantic_types:\n",
        "            if semantic_type and isinstance(semantic_type, str) and semantic_type in semantic_groups:\n",
        "                for group in semantic_groups[semantic_type]:\n",
        "                    augmented_relations_abbrev.append(('semantic_group', group))\n",
        "            else:\n",
        "                if isinstance(semantic_type, list):\n",
        "                    for st in semantic_type:\n",
        "                        if isinstance(st, str) and st in semantic_groups:\n",
        "                            for group in semantic_groups[st]:\n",
        "                                augmented_relations_abbrev.append(('semantic_group', group))\n",
        "\n",
        "        for i, relation in enumerate(abbrev_relations):\n",
        "            if relation:\n",
        "                if isinstance(relation, (list, tuple)) and len(relation) >= 2:\n",
        "                    r, related_concept = relation[:2]\n",
        "                    augmented_relations_abbrev.append((r, related_concept))\n",
        "                else:\n",
        "                    for r, related_concept in relation:\n",
        "                        augmented_relations_abbrev.append((r, related_concept))\n",
        "                        if isinstance(related_concept, list):\n",
        "                            for st in related_concept:\n",
        "                                if isinstance(st, str) and st in semantic_groups:\n",
        "                                    for group in semantic_groups[st]:\n",
        "                                        augmented_relations_abbrev.append(('semantic_group', group))\n",
        "\n",
        "\n",
        "        # Add semantic group to context relations\n",
        "        augmented_relations_context = []\n",
        "        for semantic_type in context_semantic_types:\n",
        "            if semantic_type and isinstance(semantic_type, str) and semantic_type in semantic_groups:\n",
        "                for group in semantic_groups[semantic_type]:\n",
        "                    augmented_relations_context.append(('semantic_group', group))\n",
        "            else:\n",
        "                if isinstance(semantic_type, list):\n",
        "                    for st in semantic_type:\n",
        "                        if isinstance(st, str) and st in semantic_groups:\n",
        "                            for group in semantic_groups[st]:\n",
        "                                augmented_relations_context.append(('semantic_group', group))\n",
        "\n",
        "        if context_relations:\n",
        "            if isinstance(context_relations, str):\n",
        "                try:\n",
        "                    context_relations = ast.literal_eval(context_relations)\n",
        "                except (SyntaxError, ValueError):\n",
        "                    print(f\"Warning: Could not parse context_relations for row {index}: {context_relations}\")\n",
        "                    context_relations = []\n",
        "            for relation_list in context_relations:\n",
        "                if not isinstance(relation_list, (list, tuple)):\n",
        "                    print(f\"Warning: Skipping invalid relation_list in row {index}: {relation_list}\")\n",
        "                    continue\n",
        "                if len(relation_list) == 1:\n",
        "                    relation = \"related_to\"\n",
        "                    related_concept = relation_list[0]\n",
        "                elif len(relation_list) >= 2:\n",
        "                    relation, related_concept = relation_list[:2]\n",
        "                else:\n",
        "                    for relation, related_concept in relation_list:\n",
        "                        augmented_relations_context.append((relation, related_concept))\n",
        "\n",
        "\n",
        "        # Add semantic group to gold relations\n",
        "        augmented_relations_gold = []\n",
        "        if gold_semantic_types:\n",
        "            for semantic_type in gold_semantic_types:\n",
        "                if semantic_type in semantic_groups:\n",
        "                    for group in semantic_groups[semantic_type]:\n",
        "                        augmented_relations_gold.append((\"semantic_group\", group))\n",
        "\n",
        "        if gold_relations:\n",
        "            if isinstance(gold_relations, str):\n",
        "                try:\n",
        "                    gold_relations = ast.literal_eval(gold_relations)\n",
        "                except (SyntaxError, ValueError):\n",
        "                    print(f\"Warning: Could not parse gold_relations for row {index}: {gold_relations}\")\n",
        "                    gold_relations = []\n",
        "            for relation_list in gold_relations:\n",
        "                if not isinstance(relation_list, (list, tuple)):\n",
        "                    print(f\"Warning: Skipping invalid relation_list in row {index}: {relation_list}\")\n",
        "                    continue\n",
        "                if len(relation_list) == 1:\n",
        "                    relation = \"related_to\"\n",
        "                    related_concept = relation_list[0]\n",
        "                elif len(relation_list) >= 2:\n",
        "                    relation, related_concept = relation_list[:2]\n",
        "                else:\n",
        "                    for relation, related_concept in relation_list:\n",
        "                        augmented_relations_gold.append((relation, related_concept))\n",
        "\n",
        "\n",
        "        augmented_relations_all_abbrev.append(augmented_relations_abbrev)\n",
        "        augmented_relations_all_context.append(augmented_relations_context)\n",
        "        augmented_relations_all_gold.append(augmented_relations_gold)\n",
        "\n",
        "    df[\"abbrev_relations\"] = augmented_relations_all_abbrev\n",
        "    df[\"context_relations\"] = augmented_relations_all_context\n",
        "    df[\"gold_relations\"] = augmented_relations_all_gold\n",
        "    return df\n",
        "\n",
        "# Add semantic groups to relations\n",
        "filtered_df = add_semantic_group_to_relations(df, semantic_groups)\n",
        "print(\"Filtered DataFrame with context features and semantic group relations added:\")\n",
        "# Save dataframe with labels\n",
        "filtered_df.to_csv(\"MSH_All_dataset_with_GoldRelations_withcontext_SGroup.csv\", index=False)\n",
        "filtered_df.head(20)"
      ],
      "metadata": {
        "id": "Xyfu3HCWN3xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding Gold_cui_encoding column**"
      ],
      "metadata": {
        "id": "d5GS1AUkqdMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"MSH_All_dataset_with_GoldRelations_withcontext.csv\")\n",
        "def create_semantic_type_mapping(df):\n",
        "    semantic_types = set()\n",
        "    for index, row in df.iterrows():\n",
        "         semantic_types_list = row['GOLD_CUI_semantic_types'] if pd.notna(row['GOLD_CUI_semantic_types']) else []\n",
        "         semantic_types.update(semantic_types_list)\n",
        "\n",
        "    semantic_type_mapping = {stype: index for index, stype in enumerate(semantic_types)}\n",
        "    return semantic_type_mapping\n",
        "\n",
        "def add_gold_semantic_type_encoding(df, semantic_type_mapping):\n",
        "     gold_semantic_types = []\n",
        "     for index, row in df.iterrows():\n",
        "          semantic_types_list = row['GOLD_CUI_semantic_types'] if pd.notna(row['GOLD_CUI_semantic_types']) else [] # if pd.notna(row['GOLD_CUI_semantic_types']) else '' # get semantic types from the CUI\n",
        "          semantic_type = semantic_types_list[0] if semantic_types_list else None  # Get the first one. Remove this if you want all of them\n",
        "          gold_semantic_types.append(semantic_type_mapping.get(semantic_type, -1) if isinstance(semantic_type, str) else -1) # handles cases where the semantic type is not available\n",
        "\n",
        "     df['GOLD_SEMANTIC_ENCODING'] = gold_semantic_types\n",
        "     return df\n",
        "semantic_type_mapping = create_semantic_type_mapping(df)\n",
        "gold_df = add_gold_semantic_type_encoding(df, semantic_type_mapping)\n",
        "gold_df.to_csv(\"MSH_All_dataset_with_GoldRelations_withcontext_last.csv\", index=False)\n",
        "print(\"Filtered DataFrame with context features and semantic group relations added:\")\n",
        "gold_df['GOLD_SEMANTIC_ENCODING'].value_counts()"
      ],
      "metadata": {
        "id": "lPRENpmXqj1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gold_df[gold_df['GOLD_SEMANTIC_ENCODING']==-1]"
      ],
      "metadata": {
        "id": "dtJuPjhuIZs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding concept names of abbreviation column to use as cui-specific in some tests**\n"
      ],
      "metadata": {
        "id": "wkFv0toQXuX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./data/data.csv\")\n",
        "#df.head(20)"
      ],
      "metadata": {
        "id": "_tSV49_fkR_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPt5nBD81hg5"
      },
      "outputs": [],
      "source": [
        "# Cache UMLS results to avoid repeated API calls\n",
        "umls_cache = {}  # Dictionary to store cached UMLS results\n",
        "\n",
        "\n",
        "def search_abbrev_umls(abbrev):\n",
        "    \"\"\"\n",
        "    Searches for concepts in UMLS Metathesaurus, using a cache to avoid redundant API calls.\n",
        "    \"\"\"\n",
        "    cuis = []\n",
        "    concept_names = []\n",
        "    uris = []\n",
        "    term =abbrev\n",
        "    for term in abbrev:\n",
        "      if term != 'nan':\n",
        "        if term in umls_cache:\n",
        "            cui, concept_name,uri = umls_cache[term]\n",
        "        else:\n",
        "            try:\n",
        "                response = requests.get(\n",
        "                    f\"{UMLS_API_URL}/search/current\",\n",
        "                    params={\n",
        "                        \"string\": term,\n",
        "                        \"apiKey\": UMLS_API_KEY,\n",
        "                        # \"searchType\": \"exact\",\n",
        "                    },\n",
        "                )\n",
        "                response.raise_for_status()\n",
        "                data = response.json()\n",
        "\n",
        "                if data[\"result\"][\"results\"]:\n",
        "                    cui = data[\"result\"][\"results\"][0][\"ui\"]\n",
        "                    concept_name = data[\"result\"][\"results\"][0][\"name\"]\n",
        "                    uri = data[\"result\"][\"results\"][0].get(\"uri\", None)\n",
        "\n",
        "\n",
        "                else:\n",
        "                    cui, concept_name, uri = None, None, None\n",
        "\n",
        "\n",
        "                umls_cache[term] = (cui, concept_name, uri)  # Cache the result\n",
        "\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Error searching UMLS for abbrev '{abbrev}': {e}\")\n",
        "                cui, concept_name, uri = None, None, None\n",
        "\n",
        "        #cuis.append(cui)\n",
        "        concept_names.append(concept_name)\n",
        "        #uris.append(uri)\n",
        "      else:\n",
        "        concept_names.append(None)\n",
        "        #uris.append(None)\n",
        "    if len(concept_names) <2:\n",
        "      concept_names.append(None)\n",
        "      #uris.append(None)\n",
        "    return concept_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGWMzNcW6rA6"
      },
      "outputs": [],
      "source": [
        "def add_cui_columns(df):\n",
        "    \"\"\"\n",
        "    Adds \"EXTRACTED_ABBREV_CUI\" and \"LABEL_CUI\" columns to the DataFrame\n",
        "    based on the existing 'ABBREV' and 'LABEL' columns.\n",
        "    \"\"\"\n",
        "\n",
        "    def get_cuis_concept_name(row):\n",
        "        abbrev = row['ABBREV_CUI']\n",
        "        #label = row['LABEL']\n",
        "\n",
        "        #abbrev_cui = []\n",
        "        #label_cui = []\n",
        "        abbrev_conceptNames = []\n",
        "        #label_conceptNames = []\n",
        "\n",
        "        if abbrev:\n",
        "          # Ensure abbrev is a list before calling search_abbrev_umls\n",
        "            if isinstance(abbrev, str):\n",
        "                try:\n",
        "                    abbrev = ast.literal_eval(abbrev)\n",
        "                except (SyntaxError, ValueError):\n",
        "                    abbrev = [abbrev]  # Treat as single item if eval fails\n",
        "\n",
        "                abbrev_conceptNames = search_abbrev_umls(abbrev)\n",
        "                progress_bar.update(1)\n",
        "\n",
        "            else:\n",
        "                print(\"Not string\")\n",
        "                abbrev_conceptNames = search_abbrev_umls(abbrev)\n",
        "\n",
        "                progress_bar.update(1)\n",
        "\n",
        "\n",
        "        #if isinstance(label, str):\n",
        "            #label_cui, label_conceptNames,label_uri = search_label_umls(label)\n",
        "\n",
        "        return abbrev_conceptNames\n",
        "        #return label_cui, label_conceptNames, label_uri\n",
        "\n",
        "    #df[['LABEL_CUI','LABEL_CONCEPTNAME','LABEL_URI']] = df.apply(get_cuis_concept_name, axis=1, result_type='expand')\n",
        "    df['concept_names'] = df.apply(get_cuis_concept_name, axis=1)\n",
        "    print(\"Added 'concept_names' column to DataFrame successfully.\")\n",
        "    return df\n",
        "\n",
        "# Add the new columns with CUI\n",
        "progress_bar = tqdm(range(len(df)))\n",
        "cui_df = add_cui_columns(df[:28000])\n",
        "\n",
        "# Save the updated dataframe to a new csv file\n",
        "NEW_CSV_FILE_PATH = \"MSH_All_dataset_with_GoldRelations_withcontext_last.csv\"\n",
        "cui_df.to_csv(NEW_CSV_FILE_PATH, index=False, encoding='utf-8')\n",
        "print(f\"Saved updated CSV to: {NEW_CSV_FILE_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cui_df.head(20)"
      ],
      "metadata": {
        "id": "taIcoBCG0ZnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./data/data.csv\")\n",
        "df['concept_names'] = [[] for _ in range(len(df))]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  # Get the existing concept names from the 'ABBREV_CONCEPTNAME' column\n",
        "  cui_concept_names = ast.literal_eval(row['ABBREV_CONCEPTNAME']) if pd.notna(row['ABBREV_CONCEPTNAME']) else []\n",
        "  # Append the 'LABEL' to the list of concept names\n",
        "  cui_concept_names.append(ast.literal_eval(row['LABEL_CONCEPTNAME'])[0])\n",
        "  # Assign the updated list of concept names to the 'concept_names' column for the current row\n",
        "  df.at[index, 'concept_names'] = cui_concept_names\n",
        "\n",
        "\n",
        "# Save to file\n",
        "\n",
        "df.to_csv(\"./data/data2.csv\", index=False)"
      ],
      "metadata": {
        "id": "Bw_cyS2lXtxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------**New  Level**--------\n",
        "**Semantic embedding**"
      ],
      "metadata": {
        "id": "My5pUITe7pYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**implement the semantic types embedding and semantic relations embedding using Word2Vec model**"
      ],
      "metadata": {
        "id": "w7nT8jrVib2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import ast\n",
        "\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Define parameters\n",
        "EMBEDDING_DIM = 32  # Dimension for Word2Vec embeddings\n",
        "WINDOW_SIZE = 3  # Window size for Word2Vec\n",
        "MIN_COUNT = 1 # Minimum count\n",
        "SG = 1  # Use skip-gram architecture\n",
        "CSV_FILE_PATH = \"./data/data.csv\"  # Path to your CSV file with semantic types and relations\n",
        "OUTPUT_EMBEDDINGS_PATH = \"data_semantic_type_embeddings_last.txt\" # Path to save semantic type embeddings\n",
        "OUTPUT_RELATIONS_PATH = \"data_semantic_relation_embeddings_last.txt\" # Path to save semantic relation embeddings\n",
        "VOCAB_SEMANTIC_TYPES_PATH = \"data_semantic_type_vocab_last.txt\" #Path to save vocabulary for semantic types\n",
        "VOCAB_RELATIONS_PATH = \"data_semantic_relation_vocab_last.txt\" #Path to save vocabulary for relations\n",
        "CONTEXT_WINDOW_SIZE = 5\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "def load_and_prepare_data(csv_file_path):\n",
        "    \"\"\"\n",
        "    Loads the data from the CSV file, and create the training data for Word2Vec.\n",
        "\n",
        "    Args:\n",
        "       csv_file_path: Path to the csv file.\n",
        "\n",
        "    Returns:\n",
        "         A list of lists of strings representing the training data.\n",
        "         A set with unique semantic types.\n",
        "          A set with unique semantic relations.\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "    semantic_type_sentences = []\n",
        "    semantic_relations_sentences = []\n",
        "\n",
        "    all_semantic_types = set()\n",
        "    all_relations = set()\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        abbrev_cui_semantic_types = ast.literal_eval(row['abbrev_cui_semantic_types']) if pd.notna(row['abbrev_cui_semantic_types']) else []\n",
        "        # Check if 'context_semantic_types' is a string and try to convert it to a list\n",
        "\n",
        "        # context_semantic_types = ast.literal_eval(row[\"context_semantic_types\"]) #if isinstance(row[\"context_semantic_types\"], str) and row[\"context_semantic_types\"] != 'nan' else []\n",
        "        gold_semantic_types = row['GOLD_CUI_semantic_types'] if pd.notna(row['GOLD_CUI_semantic_types']) else [] # get semantic types from the CUI\n",
        "\n",
        "        abbrev_relations = ast.literal_eval(row['abbrev_cui_relations']) #if pd.notna(row['abbrev_cui_relations']) else []\n",
        "        #context_relations = ast.literal_eval(row[\"context_relations\"]) if isinstance(row[\"context_relations\"], str) and row[\"context_relations\"] != 'nan' else []\n",
        "        gold_relations = row[\"GOLD_CUI_relations\"] if pd.notna(row[\"GOLD_CUI_relations\"]) else []\n",
        "\n",
        "\n",
        "\n",
        "        if abbrev_cui_semantic_types:\n",
        "            semantic_type_sentences.append(abbrev_cui_semantic_types)\n",
        "        #if context_semantic_types:\n",
        "          #semantic_type_sentences.append(context_semantic_types)\n",
        "        if gold_semantic_types:\n",
        "            semantic_type_sentences.append(gold_semantic_types)\n",
        "\n",
        "\n",
        "        if abbrev_relations:\n",
        "            semantic_relations_sentences.extend([relation for relation in abbrev_relations])\n",
        "        #if context_relations:\n",
        "          #semantic_relations_sentences.extend([relation for relation in context_relations])\n",
        "        if gold_relations:\n",
        "            semantic_relations_sentences.extend([relation for relation in gold_relations])\n",
        "\n",
        "        # Fix: Iterate over the lists and add individual elements to the sets\n",
        "        for item in abbrev_cui_semantic_types:\n",
        "            # Check if the item is a list, if so, iterate through it\n",
        "            if isinstance(item, list):\n",
        "                for subitem in item:\n",
        "                    all_semantic_types.add(subitem)\n",
        "            else:\n",
        "                all_semantic_types.add(item)  # Use add instead of update\n",
        "\n",
        "        # Similar check and handling for gold_semantic_types\n",
        "        if isinstance(gold_semantic_types, list):\n",
        "            for item in gold_semantic_types:\n",
        "                # Check if the item is a list, if so, iterate through it\n",
        "                if isinstance(item, list):\n",
        "                    for subitem in item:\n",
        "                        all_semantic_types.add(subitem)\n",
        "                else:\n",
        "                    all_semantic_types.add(item)\n",
        "        else:\n",
        "            all_semantic_types.add(gold_semantic_types)\n",
        "\n",
        "        for item in abbrev_relations:\n",
        "             if isinstance(item, list):\n",
        "                for subitem in item:\n",
        "                    all_relations.add(subitem)\n",
        "             else:\n",
        "                all_relations.add(item)  # Use add instead of update  # Use add instead of update\n",
        "        #for item in context_relations:\n",
        "            #all_relations.add(item)  # Use add instead of update\n",
        "        for item in gold_relations:\n",
        "            all_relations.add(item)  # Use add instead of update\n",
        "\n",
        "\n",
        "\n",
        "    return semantic_type_sentences, all_semantic_types, semantic_relations_sentences, all_relations\n",
        "\n",
        "def train_word2vec_embeddings(sentences, vector_size, window, min_count, sg, output_path):\n",
        "    \"\"\"Trains Word2Vec embeddings and saves them to a file.\"\"\"\n",
        "    sentences = [[str(word) for word in sentence] for sentence in sentences if sentence]\n",
        "    model = Word2Vec(sentences=sentences, vector_size=vector_size, window=window, min_count=min_count, sg=sg)\n",
        "    model.wv.save_word2vec_format(output_path, binary=False) # Binary = false saves as text\n",
        "    print(f\"Embeddings saved to: {output_path}\")\n",
        "    return model\n",
        "\n",
        "def create_vocabulary(data, output_path):\n",
        "  \"\"\"Creates and saves a vocabulary file\"\"\"\n",
        "  with open(output_path, 'w', encoding=\"utf-8\") as f:\n",
        "    for item in data:\n",
        "       f.write(f\"{item}\\n\")\n",
        "  print(f\"Vocabulary saved to: {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "# Load data\n",
        "semantic_type_sentences, all_semantic_types, semantic_relations_sentences, all_relations  = load_and_prepare_data(CSV_FILE_PATH)\n",
        "\n",
        "# Train embeddings for Semantic Types\n",
        "print (\"Training semantic type embeddings...\")\n",
        "semantic_types_model = train_word2vec_embeddings(semantic_type_sentences, EMBEDDING_DIM, WINDOW_SIZE, MIN_COUNT, SG, OUTPUT_EMBEDDINGS_PATH)\n",
        "\n",
        "# Train embeddings for Semantic Relations\n",
        "print (\"Training semantic relation embeddings...\")\n",
        "semantic_relations_model = train_word2vec_embeddings(semantic_relations_sentences, EMBEDDING_DIM, WINDOW_SIZE, MIN_COUNT, SG, OUTPUT_RELATIONS_PATH)\n",
        "\n",
        "#Create and save vocabularies\n",
        "create_vocabulary(all_semantic_types, VOCAB_SEMANTIC_TYPES_PATH)\n",
        "create_vocabulary(all_relations, VOCAB_RELATIONS_PATH)\n",
        "\n",
        "\n",
        "print(\"All training finished\")"
      ],
      "metadata": {
        "id": "otGylERSWv3B"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}